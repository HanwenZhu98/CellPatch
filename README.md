# CellPatch: an Ultra-Efficient Foundation Model for Single-Cell RNA-seq Data with Heuristic Patching and Transformer
CellPatch addresses the sequence length limitations that commonly constrain foundation models for single-cell transcriptome data, which often create challenges in training and transfer learning. By implementing a novel gene patching method based on cross-attention mechanisms, CellPatch demonstrates exceptional performance across various tasks, including fine-tuning and transfer learning. Furthermore, the attention scores and gene embedding features generated by the model contain meaningful semantic information, validating the interpretability of the model architecture.
# Data & Checkpoint
Sample data and checkpoints are provided in the data folder. For additional training datasets, please refer to the data availability section in our paper.
# Time cost
Under test conditions using an NVIDIA A100 80GB GPU, CellPatch demonstrates remarkable efficiency. For example, in cell annotation tasks, the model can process 1,000 cells in approximately 2 seconds during inference.
![image](https://github.com/user-attachments/assets/a298ef99-abd8-4312-b965-74e7b4cef21e)
# Disclaimer
This tool is intended for research purposes only and has not been approved for clinical use.
# Copyright
This tool has been developed by Wulab at Peking University Health Science Center (BJMU).
Copyright Â© Wulab, Peking University Health Science Center (BJMU).
All rights reserved.
